name: 'Experiment Report'
description: 'Generates and archives reports comparing Develocity builds for an experiment.'

inputs:
  api-key:
    description: 'API key for accessing Develocity services'
    required: true
  url:
    description: 'URL of the Develocity server'
    required: true
  task:
    description: 'The task used in the experiment'
    required: true
  max-builds:
    description: 'Maximum number of builds to fetch for the comparison (default is 200)'
    required: false
    default: 200
  experiment-id:
    description: 'Unique identifier for the experiment'
    required: true
  tags:
    description: 'Comma-separated tags to filter the builds for comparison'
    required: true
  profile:
    description: 'Enable or disable profiling during the comparison'
    required: true
  gh_token:
    description: 'GitHub token for authentication'
    required: true
  taskpathreport:
    description: 'Enable or disable task path reporting'
    required: true
  processreport:
    description: 'Enable or disable process reporting'
    required: true
  kotlinreport:
    description: 'Enable or disable Kotlin build reporting'
    required: true
  tasktypereport:
    description: 'Enable or disable task type reporting'
    required: true
  resourceusagereport:
    description: 'Enable or disable resource usage reporting'
    required: true
  onlycacheableoutcome:
    description: 'Enable or disable reporting only for cacheable outcomes'
    required: true
  thresholdtaskduration:
    description: 'Threshold of task duration for the task path report'
    required: true
    default: 1000

runs:
  using: 'composite'
  steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Setup Java
      uses: actions/setup-java@v4
      with:
        distribution: zulu
        java-version: 17

    - name: Execute CompareGEBuilds
      id: compareBuilds
      run: |
        # Download and set permissions for the CompareGEBuilds binary
        curl -L https://github.com/cdsap/CompareGEBuilds/releases/download/v0.5.1/build-experiment-results --output build-experiment-results
        chmod 0757 build-experiment-results

        # Parse and format tags input into the required format
        tags="${{ inputs.tags }}"
        arrayTags=(${tags//,/ })
        tagsParsed=""
        for val in "${arrayTags[@]}"; do
          tagsParsed="$tagsParsed --variants=$val"
        done

        # Set optional flags based on input values
        profile=""
        if [ "${{ inputs.profile }}" == "true" ]; then
          profile="--profile"
        fi

        taskpathreport="--task-path-report"
        if [ "${{ inputs.taskpathreport }}" == "false" ]; then
          taskpathreport="--no-task-path-report"
        fi

        processreport="--process-report"
        if [ "${{ inputs.processreport }}" == "false" ]; then
          processreport="--no-process-report"
        fi

        kotlinreport="--kotlin-build-report"
        if [ "${{ inputs.kotlinreport }}" == "false" ]; then
          kotlinreport="--no-kotlin-build-report"
        fi

        tasktypereport="--task-type-report"
        if [ "${{ inputs.tasktypereport }}" == "false" ]; then
          tasktypereport="--no-task-type-report"
        fi

        resourceusagereport="--resource-usage-report"
        if [ "${{ inputs.resourceusagereport }}" == "false" ]; then
          resourceusagereport="--no-resource-usage-report"
        fi

        onlycacheableoutcome="--only-cacheable-outcome"
        if [ "${{ inputs.onlycacheableoutcome }}" == "false" ]; then
          onlycacheableoutcome="--no-only-cacheable-outcome"
        fi

        thresholdtaskduration="--threshold-task-duration ${{ inputs.thresholdtaskduration }}"

        # Execute the comparison with the appropriate arguments
        ./build-experiment-results --url=${{ inputs.url }} $tasktypereport $resourceusagereport $onlycacheableoutcome $taskpathreport $processreport $kotlinreport $thresholdtaskduration $profile --max-builds=${{ inputs.max-builds }} $tagsParsed  --api-key=${{ inputs.api-key }}

        # Output the results to the GitHub step summary
        CONTENT=$(cat experiment_results_summary_gha)
        echo "$CONTENT" >> $GITHUB_STEP_SUMMARY
      shell: bash

    - name: Archive Comparison Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: build-comparison-reports
        path: |
          experiment_results.html
          experiment_results.csv
        if-no-files-found: error

    - name: Checkout gh-pages branch
      uses: actions/checkout@v4
      with:
        ref: gh-pages
        path: .

    - name: Download experiment results
      uses: actions/download-artifact@v4
      with:
        name: build-comparison-reports
        path: temp-results

    - name: Update gh-pages content
      run: |
        TIMESTAMP=$(date +%Y-%m-%d)
        EXPERIMENT_FILE="_posts/${TIMESTAMP}-${GITHUB_SHA::8}-experiment.md"
        EXPERIMENT_FILE_HTML="${TIMESTAMP}-${GITHUB_SHA::8}-experiment.html"

        cp temp-results/experiment_results.html "reports/$EXPERIMENT_FILE_HTML"
        if [ ! -f "$EXPERIMENT_FILE" ]; then
          cat > "$EXPERIMENT_FILE" <<EOL
---
layout: post
title: "Experiment 100: Neural Network Performance"
date: 2024-03-19
report_link: /Telltale/reports/$EXPERIMENT_FILE_HTML
description: "Investigation of neural network performance under different hyperparameters"
---
EOL
        fi
      shell: bash

    - name: Commit and push to gh-pages
      run: |
        cd gh-pages-branch
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add _posts
        git add reports
        git commit -m "Add experiment results for ${GITHUB_SHA::8}"
        git push origin gh-pages
      shell: bash

    - name: Cleanup
      run: rm -rf gh-pages-branch
      shell: bash
