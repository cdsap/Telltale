name: 'Experiment Report'
description: 'Generates and archives reports comparing Develocity builds for an experiment.'

inputs:
  api-key:
    description: 'API key for accessing Develocity services'
    required: true
  url:
    description: 'URL of the Develocity server'
    required: true
  task:
    description: 'The task used in the experiment'
    required: true
  max-builds:
    description: 'Maximum number of builds to fetch for the comparison (default is 200)'
    required: false
    default: 200
  experiment-id:
    description: 'Unique identifier for the experiment'
    required: true
  tags:
    description: 'Comma-separated tags to filter the builds for comparison'
    required: true
  profile:
    description: 'Enable or disable profiling during the comparison'
    required: true
  gh_token:
    description: 'GitHub token for authentication'
    required: true
  taskpathreport:
    description: 'Enable or disable task path reporting'
    required: true
  processreport:
    description: 'Enable or disable process reporting'
    required: true
  kotlinreport:
    description: 'Enable or disable Kotlin build reporting'
    required: true
  tasktypereport:
    description: 'Enable or disable task type reporting'
    required: true
  resourceusagereport:
    description: 'Enable or disable resource usage reporting'
    required: true
  onlycacheableoutcome:
    description: 'Enable or disable reporting only for cacheable outcomes'
    required: true
  thresholdtaskduration:
    description: 'Threshold of task duration for the task path report'
    required: true
    default: 1000

runs:
  using: 'composite'
  steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Setup Java
      uses: actions/setup-java@v4
      with:
        distribution: zulu
        java-version: 17

    - name: Execute CompareGEBuilds
      id: compareBuilds
      run: |
        # Download and set permissions for the CompareGEBuilds binary
        curl -L https://github.com/cdsap/CompareGEBuilds/releases/download/v0.5.1/build-experiment-results --output build-experiment-results
        chmod 0757 build-experiment-results

        # Parse and format tags input into the required format
        tags="${{ inputs.tags }}"
        arrayTags=(${tags//,/ })
        tagsParsed=""
        for val in "${arrayTags[@]}"; do
          tagsParsed="$tagsParsed --variants=$val"
        done

        # Set optional flags based on input values
        profile=""
        if [ "${{ inputs.profile }}" == "true" ]; then
          profile="--profile"
        fi

        taskpathreport="--task-path-report"
        if [ "${{ inputs.taskpathreport }}" == "false" ]; then
          taskpathreport="--no-task-path-report"
        fi

        processreport="--process-report"
        if [ "${{ inputs.processreport }}" == "false" ]; then
          processreport="--no-process-report"
        fi

        kotlinreport="--kotlin-build-report"
        if [ "${{ inputs.kotlinreport }}" == "false" ]; then
          kotlinreport="--no-kotlin-build-report"
        fi

        tasktypereport="--task-type-report"
        if [ "${{ inputs.tasktypereport }}" == "false" ]; then
          tasktypereport="--no-task-type-report"
        fi

        resourceusagereport="--resource-usage-report"
        if [ "${{ inputs.resourceusagereport }}" == "false" ]; then
          resourceusagereport="--no-resource-usage-report"
        fi

        onlycacheableoutcome="--only-cacheable-outcome"
        if [ "${{ inputs.onlycacheableoutcome }}" == "false" ]; then
          onlycacheableoutcome="--no-only-cacheable-outcome"
        fi

        thresholdtaskduration="--threshold-task-duration ${{ inputs.thresholdtaskduration }}"

        # Execute the comparison with the appropriate arguments
        ./build-experiment-results --url=${{ inputs.url }} $tasktypereport $resourceusagereport $onlycacheableoutcome $taskpathreport $processreport $kotlinreport $thresholdtaskduration $profile --max-builds=${{ inputs.max-builds }} $tagsParsed  --api-key=${{ inputs.api-key }}

        # Output the results to the GitHub step summary
        CONTENT=$(cat experiment_results_summary_gha)
        echo "$CONTENT" >> $GITHUB_STEP_SUMMARY
      shell: bash

    - name: Archive Comparison Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: build-comparison-reports
        path: |
          experiment_results.html
          experiment_results.csv
        if-no-files-found: error

    - name: Checkout gh-pages branch
      uses: actions/checkout@v4
      with:
        ref: gh-pages
        path: .

    - name: Download experiment results
      uses: actions/download-artifact@v4
      with:
        name: build-comparison-reports
        path: temp-results

    - name: Update gh-pages content
      shell: bash
      run: |
        TIMESTAMP=$(date +%Y-%m-%d)
        EXPERIMENT_FILE="_posts/${TIMESTAMP}-${GITHUB_SHA::8}-experiment.md"
        EXPERIMENT_FILE_HTML="${TIMESTAMP}-${GITHUB_SHA::8}-experiment.html"

        cp temp-results/experiment_results.html "reports/$EXPERIMENT_FILE_HTML"

        if [ ! -f "$EXPERIMENT_FILE" ]; then
          echo "---" > "$EXPERIMENT_FILE"
          echo "layout: post" >> "$EXPERIMENT_FILE"
          echo "title: \"Experiment 100: Neural Network Performance\"" >> "$EXPERIMENT_FILE"
          echo "date: 2024-03-19" >> "$EXPERIMENT_FILE"
          echo "report_link: /Telltale/reports/$EXPERIMENT_FILE_HTML" >> "$EXPERIMENT_FILE"
          echo "description: \"Investigation of neural network performance under different hyperparameters\"" >> "$EXPERIMENT_FILE"
          echo "---" >> "$EXPERIMENT_FILE"
        fi

    - name: Push Experiment Results
      run: |
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git config --global user.name "github-actions[bot]"
        git add _posts
        git add reports
        git commit -m "Add experiment results for ${GITHUB_SHA::8}"
        git push https://x-access-token:${{ secrets.GH_PAT }}@github.com/cdsap/Telltale.git gh-pages
